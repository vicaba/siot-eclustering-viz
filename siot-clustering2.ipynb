{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import cm\n",
    "import matplotlib.cm as cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-573d9dae4264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./files/cluster.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m             )\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'frame'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 853\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             decoded = {str(k): v for k, v in compat.iteritems(\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "clusters = pd.read_json(\"./files/cluster.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSteps(data):\n",
    "    for runIdx in range(0, len(data)):\n",
    "        fig, ax = plt.subplots()\n",
    "        iteration = data.iloc[runIdx][\"iteration\"]\n",
    "        clusters = data.iloc[runIdx][\"clusters\"]\n",
    "        norm = colors.Normalize(vmin=0, vmax=len(clusters))\n",
    "        print(\"iteration: %s, clusters: %s\" % (iteration, len(clusters)))\n",
    "        for cIdx in range(0, len(clusters)):\n",
    "            rgba_color = cm.gnuplot(norm(cIdx))\n",
    "            pointsX = [point[0] for point in clusters[cIdx][\"points\"]]\n",
    "            pointsY = [point[1] for point in clusters[cIdx][\"points\"]]\n",
    "            ax.scatter(pointsX, pointsY, color=rgba_color)\n",
    "            ax.scatter(clusters[cIdx][\"centroid\"][0], clusters[cIdx][\"centroid\"][1], color=rgba_color, marker=\"+\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSteps(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(data):\n",
    "    for runIdx in range(0, len(data)):\n",
    "        fig, ax = plt.subplots()\n",
    "        clusters_step1 = data.iloc[runIdx][\"steps\"][0][\"clusters\"]\n",
    "        clusters_step2 = data.iloc[runIdx][\"steps\"][1][\"clusters\"]\n",
    "        norm = colors.Normalize(vmin=0, vmax=len(clusters_step1))\n",
    "        for cIdx in range(0, len(clusters_step1)):\n",
    "            rgba_color = cm.gnuplot(norm(cIdx))\n",
    "            ax.plot(clusters_step1[cIdx][\"syntheticCenter\"], \"--\", color=rgba_color, label=\"cluster %s\" % cIdx)\n",
    "            ax.plot(clusters_step2[cIdx][\"syntheticCenter\"], color=rgba_color, label=\"cluster %s - rescheduled\" % cIdx)\n",
    "            print(clusters_step2[cIdx][\"metric\"])\n",
    "        ax.legend(bbox_to_anchor=(1, -0.3), loc=4, borderaxespad=0.)\n",
    "\n",
    "        ax.set(xlabel='Hours', ylabel='Power (kW)',title='')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggm(summary, file_name=None): \n",
    "    fig, ax = plt.subplots()\n",
    "    rgba_color = cm.gnuplot(norm(0))\n",
    "    ax.plot(range(1, len(summary[\"s1. agg m\"]) + 1), summary[\"s1. agg m\"], \"--\", color=rgba_color, label=\"s1. agg m\")\n",
    "    ax.plot(range(1, len(summary[\"s2. agg m\"]) + 1), summary[\"s2. agg m\"], color=rgba_color, label=\"s2. agg m\")\n",
    "    lgd = ax.legend(bbox_to_anchor=(1, -0.3), loc=4, borderaxespad=0.)\n",
    "    ax.set(xlabel='K clusters', ylabel='Aggregate PAR',title='')\n",
    "    plt.show()\n",
    "    if file_name is not None:\n",
    "        fig.savefig(file_name, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    return fig\n",
    "    \n",
    "def plot_maxm(summary, file_name=None): \n",
    "    fig, ax = plt.subplots()\n",
    "    rgba_color = cm.gnuplot(norm(0))\n",
    "    ax.plot(range(1, len(summary[\"s1. agg m\"]) + 1), summary[\"s1. max m\"], \"--\", color=rgba_color, label=\"s1. max m\")\n",
    "    ax.plot(range(1, len(summary[\"s2. agg m\"]) + 1), summary[\"s2. max m\"], color=rgba_color, label=\"s2. max m\")\n",
    "    lgd = ax.legend(bbox_to_anchor=(1, -0.3), loc=4, borderaxespad=0.)\n",
    "    ax.set(xlabel='K clusters', ylabel='Max. Aggregate PAR',title='')\n",
    "    plt.show()\n",
    "    if file_name is not None:\n",
    "        fig.savefig(file_name, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    return fig\n",
    "    \n",
    "def plot_peak(summary, file_name=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    rgba_color = cm.gnuplot(norm(0))\n",
    "    ax.plot(range(1, len(summary[\"s1. agg m\"]) + 1), summary[\"s1. peak\"], \"--\", color=rgba_color, label=\"s1. peak\")\n",
    "    ax.plot(range(1, len(summary[\"s2. agg m\"]) + 1), summary[\"s2. peak\"], color=rgba_color, label=\"s2. peak\")\n",
    "    lgd = ax.legend(bbox_to_anchor=(1, -0.3), loc=4, borderaxespad=0.)\n",
    "    ax.set(xlabel='K clusters', ylabel='Peak power (kW)',title='')\n",
    "    plt.show()\n",
    "    if file_name is not None:\n",
    "        fig.savefig(file_name, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAR Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryBatch_global = pd.read_json(\"./files/summaryBatch.json\")\n",
    "#summaryBatch_global = summaryBatch_global[[\"k\",\"clusters\",\"s1. agg m\",\"s1. max m\",\"s1. peak\",\"s2. agg m\",\"s2. max m\",\"s2. peak\",\"total m\"]]\n",
    "#batch_global = pd.read_json(\"./files/batch.json\")\n",
    "\n",
    "k = 2\n",
    "sampleSizeMin = 0.8\n",
    "sampleSizeMax = 1.0\n",
    "steps = 1\n",
    "\n",
    "\n",
    "def sampleSizeRange():\n",
    "    return (x/10 for x in range(int(sampleSizeMin * 10), int((sampleSizeMax * 10) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>clusters</th>\n",
       "      <th>k</th>\n",
       "      <th>s1. agg m</th>\n",
       "      <th>s1. max m</th>\n",
       "      <th>s1. peak</th>\n",
       "      <th>s2. agg m</th>\n",
       "      <th>s2. max m</th>\n",
       "      <th>s2. peak</th>\n",
       "      <th>total m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sampleSize</th>\n",
       "      <th>split</th>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>[50]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.451786</td>\n",
       "      <td>1.451786</td>\n",
       "      <td>171.170633</td>\n",
       "      <td>1.451786</td>\n",
       "      <td>1.451786</td>\n",
       "      <td>171.170633</td>\n",
       "      <td>1.451786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[25, 25]</td>\n",
       "      <td>2</td>\n",
       "      <td>1.136210</td>\n",
       "      <td>1.843565</td>\n",
       "      <td>105.326017</td>\n",
       "      <td>1.136210</td>\n",
       "      <td>1.843565</td>\n",
       "      <td>105.326017</td>\n",
       "      <td>1.451786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    clusters  k  s1. agg m  s1. max m    s1. peak  s2. agg m  \\\n",
       "sampleSize split k                                                             \n",
       "1.0        0     1      [50]  1   1.451786   1.451786  171.170633   1.451786   \n",
       "                 2  [25, 25]  2   1.136210   1.843565  105.326017   1.136210   \n",
       "\n",
       "                    s2. max m    s2. peak   total m  \n",
       "sampleSize split k                                   \n",
       "1.0        0     1   1.451786  171.170633  1.451786  \n",
       "                 2   1.843565  105.326017  1.451786  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = []\n",
    "step_list = []\n",
    "\n",
    "for i in range(0 , len(summaryBatch_global)):\n",
    "    register = summaryBatch_global.iloc[i]\n",
    "    \n",
    "    crossfold = json_normalize(register[\"crossfold\"])\n",
    "    splits = crossfold[\"splits\"].values[0]\n",
    "    steps = summaryBatch_global.iloc[i][\"step\"]\n",
    "    for j in range(0, splits):\n",
    "        step = json_normalize(steps[j])\n",
    "        for ki in range(1, k+1):\n",
    "            index_list.append((float(\"{0:.2f}\".format(crossfold[\"sampleSize\"].values[0])), j, ki))\n",
    "            step_list.append(step.iloc[ki-1])\n",
    "        \n",
    "    \n",
    "json_normalize(summaryBatch_global.iloc[0][\"crossfold\"])\n",
    "json_normalize(summaryBatch_global.iloc[0][\"step\"][0])\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index_list, names=[\"sampleSize\", \"split\", \"k\"])\n",
    "summaryBatch_global_treated = pd.DataFrame(step_list, index=index)\n",
    "summaryBatch_global_treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2 = 2\n",
    "query = f\"k == {k2} and sampleSize == {sampleSizeMin}\"\n",
    "summaryBatch_global_treated.query(query)[\"s1. agg m\"].mean()\n",
    "summaryBatch_global_treated.query(query)[\"s1. max m\"].mean()\n",
    "summaryBatch_global_treated.query(query)[\"s1. peak\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summaryBatch.tex','w') as tf:\n",
    "    tf.write(summaryBatch_global.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-35a85c1a1636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \"s1. peak\" : summaryBatch_global_treated.query(query)[\"s1. peak\"].mean()}\n\u001b[1;32m     12\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"s1. agg m\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s1. max m\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"s1. peak\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             data.update({\"s2. agg m\" : summaryBatch_global_treated.query(query)[\"s2. agg m\"].mean(),\n\u001b[1;32m     15\u001b[0m                 \u001b[0;34m\"s2. max m\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msummaryBatch_global_treated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"s2. max m\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "index_list = []\n",
    "step_list = []\n",
    "\n",
    "for j in range(1, k+1):\n",
    "    for ssize in sampleSizeRange():\n",
    "        \n",
    "        index_list.append((ssize, \"mean\", j))\n",
    "        query = f\"k == {j} and sampleSize == {ssize}\"\n",
    "        data = {\"s1. agg m\" : summaryBatch_global_treated.query(query)[\"s1. agg m\"].mean(),\n",
    "                \"s1. max m\" : summaryBatch_global_treated.query(query)[\"s1. max m\"].mean(), \n",
    "                \"s1. peak\" : summaryBatch_global_treated.query(query)[\"s1. peak\"].mean()}\n",
    "        index = [\"s1. agg m\",\"s1. max m\",\"s1. peak\"]\n",
    "        if (steps >= 2):\n",
    "            data.update({\"s2. agg m\" : summaryBatch_global_treated.query(query)[\"s2. agg m\"].mean(),\n",
    "                \"s2. max m\" : summaryBatch_global_treated.query(query)[\"s2. max m\"].mean(), \n",
    "                \"s2. peak\" : summaryBatch_global_treated.query(query)[\"s2. peak\"].mean()})\n",
    "            index = index + [\"s2. agg m\",\"s2. max m\",\"s2. peak\"]\n",
    "            \n",
    "        s = pd.Series(data,index=index) \n",
    "        step_list.append(s)\n",
    "        #print(f\"sampleSize = {ssize}, k = {j}\")\n",
    "        \n",
    "        index_list.append((ssize, \"stdv\", j))\n",
    "        query = f\"k == {j} and sampleSize == {ssize}\"\n",
    "        data = {\"s1. agg m\" : summaryBatch_global_treated.query(query)[\"s1. agg m\"].std(),\n",
    "                \"s1. max m\" : summaryBatch_global_treated.query(query)[\"s1. max m\"].std(), \n",
    "                \"s1. peak\" : summaryBatch_global_treated.query(query)[\"s1. peak\"].std()}\n",
    "        index = [\"s1. agg m\",\"s1. max m\",\"s1. peak\"]\n",
    "        if (steps >= 2):\n",
    "            data.update({\"s2. agg m\" : summaryBatch_global_treated.query(query)[\"s2. agg m\"].std(),\n",
    "                \"s2. max m\" : summaryBatch_global_treated.query(query)[\"s2. max m\"].std(), \n",
    "                \"s2. peak\" : summaryBatch_global_treated.query(query)[\"s2. peak\"].std()})\n",
    "            index = index + [\"s2. agg m\",\"s2. max m\",\"s2. peak\"]\n",
    "            \n",
    "        s = pd.Series(data,index=index) \n",
    "        step_list.append(s)\n",
    "\n",
    "        \n",
    "index = pd.MultiIndex.from_tuples(index_list, names=[\"sampleSize\", \"metric\", \"k\"])\n",
    "summaryBatch_global_statistics = pd.DataFrame(step_list, index=index)\n",
    "summaryBatch_global_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>[0.095904899031]</td>\n",
       "      <td>[0.0748629667593]</td>\n",
       "      <td>[0.0625413514146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>[0.061754706342]</td>\n",
       "      <td>[0.0584759944394]</td>\n",
       "      <td>[0.0608020632314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0387179838613]</td>\n",
       "      <td>[0.109939285615]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1                  2                  3\n",
       "0.8  [0.095904899031]  [0.0748629667593]  [0.0625413514146]\n",
       "0.9  [0.061754706342]  [0.0584759944394]  [0.0608020632314]\n",
       "1.0             [0.0]  [0.0387179838613]   [0.109939285615]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMetrics(metric, summaryMetric):\n",
    "\n",
    "    index_list = [sampleSizeRange()]\n",
    "    cols = [x for x in range(1, k+1)]\n",
    "    step_list = []\n",
    "\n",
    "    for ssize in sampleSizeRange():\n",
    "        query = f\"sampleSize == {ssize} and metric == \\\"{summaryMetric}\\\" \"\n",
    "        dataAllK = summaryBatch_global_statistics.query(query)[f\"{metric}\"]\n",
    "        dictAllK = {}\n",
    "        for j in range(1, k+1):\n",
    "            d = dataAllK.reset_index().query(f\"k == {j}\")[f\"{metric}\"]\n",
    "            dictAllK[f\"{j}\"] = d.values\n",
    "        s = pd.Series(dictAllK, name=f\"{ssize}\")\n",
    "        step_list.append(s)\n",
    "\n",
    "    return pd.DataFrame(step_list)\n",
    "    \n",
    "getMetrics(\"s1. agg m\", \"mean\")\n",
    "getMetrics(\"s1. agg m\", \"stdv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160780</td>\n",
       "      <td>0.312639</td>\n",
       "      <td>0.737680</td>\n",
       "      <td>0.495611</td>\n",
       "      <td>0.765506</td>\n",
       "      <td>0.827995</td>\n",
       "      <td>0.063007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.523206</td>\n",
       "      <td>0.113421</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>0.969279</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.627076</td>\n",
       "      <td>0.023188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.393152</td>\n",
       "      <td>0.257559</td>\n",
       "      <td>0.556803</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>0.596032</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>0.471754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e         f         g\n",
       "0  0.160780  0.312639  0.737680  0.495611  0.765506  0.827995  0.063007\n",
       "1  0.523206  0.113421  0.479314  0.969279  0.025397  0.627076  0.023188\n",
       "2  0.393152  0.257559  0.556803  0.020505  0.596032  0.200862  0.471754"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = [pd.Series(np.random.rand(3), name=c) for c in list('abcdefg')]\n",
    "series\n",
    "pd.DataFrame.from_items([(s.name, s) for s in series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
